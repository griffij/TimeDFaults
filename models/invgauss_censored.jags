# Use parameterisation from Matthews (2002) BSSA paper
# Number of censored observations
data {
 for (i in 1:N){
 zeros[i] = 0
 }
 C = 10000
}
model{
  for (i in 1:N){
   # Prior for lambda parameter
  zeros[i] ~ dpois(zeros.mean[i])
  zeros.mean[i] = -l[i] + C
  # Censoring
  y[i] = ifelse(isCensored[i], censorLimitVec[i], Y[i])
  # For calculating CDF later
  u1[i] = (1/alpha)*(pow(y[i], 1/2)*pow(mu, -1/2) -
  	pow(y[i], -1/2)*pow(mu, 1/2))
  u2[i] = (1/alpha)*(pow(y[i], 1/2)*pow(mu, -1/2) +
  	pow(y[i], -1/2)*pow(mu, 1/2))
  cdf[i] = pnorm(u1[i],0,1) + exp(2/(pow(alpha, 2)))*pnorm(-1*u2[i],0,1)
  # Log-likelihood 
  l[i] = ifelse(isCensored[i],
       log(1-cdf[i]),
       0.5 * (log(mu) - log(2*3.14) - 2*log(alpha) - 3*log(y[i])) -
       0.5*pow((y[i] - mu), 2)/(mu*pow(alpha,2)*y[i])
       )
    }

#alpha ~ dt(0,0.04,3)T(0.01,)
alpha ~ dunif(0, 10)
#mu ~ dnorm(0, 10e-4)T(0,)
# Dunstan priors on mean
#mu ~ dnorm(15000, 4e-8)T(0,30000.0) # Maximum value based on known number of events in trench
mu ~ dunif(0.1, 200000)
#alpha ~ dgamma(0.0001, 0.0001)
}